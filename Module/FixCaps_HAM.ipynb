{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "uuid": "5cde640c-432f-4f8a-9f00-017bf8c65e34"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys, os\n",
    "import json\n",
    "import torch.nn as nn  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import prettytable\n",
    "import time\n",
    "sys.setrecursionlimit(15000)\n",
    "from thop.profile import profile\n",
    "\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from images_show import ImageShow\n",
    "from model import FixCapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "uuid": "a391afe8-e37b-4ef6-ab2e-c0bdbb7849ee"
   },
   "outputs": [],
   "source": [
    "# Settings.\n",
    "sys.path.append(os.pardir)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "img_title = \"HAM10000\"#\"COVID-19\"#\"ISIC2019\"#\"skin_lesion\"#\n",
    "best_acc= 0.\n",
    "eval_acc = 0.\n",
    "# write = SummaryWriter()\n",
    "#defined \n",
    "try:\n",
    "    print(len(train_acc_list))\n",
    "except NameError:\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "    test_auc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "#activate ImageShow\n",
    "show = ImageShow(train_loss_list = train_loss_list,\n",
    "                 train_acc_list = train_acc_list,\n",
    "                test_loss_list = test_loss_list,\n",
    "                test_acc_list = test_acc_list,\n",
    "                test_auc_list = test_auc_list,\n",
    "                val_loss_list = val_loss_list,\n",
    "                val_acc_list = val_acc_list,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop((299, 299)),\n",
    "                                 transforms.RandomVerticalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"val\": transforms.Compose([transforms.Resize((308, 308)),\n",
    "                               transforms.CenterCrop((299, 299)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ]),\n",
    "    \"test\": transforms.Compose([transforms.Resize((316,316)),\n",
    "                               transforms.CenterCrop((299, 299)),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "    }\n",
    "train_doc = \"train525e384\"\n",
    "val_doc = \"val525e384png\"\n",
    "test_doc = \"test525png384\"\n",
    "\n",
    "data_root = os.path.abspath(os.path.join(os.getcwd(),\"..\"))  # get data root path\n",
    "image_path = os.path.join(data_root, \"datasets\",\"HAM10000\")#\n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(image_path,train_doc),#\n",
    "                                     transform=data_transform[\"train\"])\n",
    "val_dataset = datasets.ImageFolder(root=os.path.join(image_path,val_doc),\n",
    "                                        transform=data_transform[\"val\"])\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(image_path,test_doc),\n",
    "                                        transform=data_transform[\"test\"])\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "val_num = len(val_dataset)\n",
    "test_num = len(test_dataset)\n",
    "\n",
    "# img_sample = Image.open(test_dataset.imgs[1][0])\n",
    "n_channels = 3#np.array(img_sample).shape[2]#(H,W,C)\n",
    "\n",
    "data_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in data_list.items())\n",
    "n_classes  = len(data_list)\n",
    "print(f'Using {n_classes } classes.')\n",
    "# write dict into json file\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open(f'{img_title}.json', 'w') as json_file:#class_indices\n",
    "    json_file.write(json_str)\n",
    "    \n",
    "BatchSize = 168#128#188\n",
    "V_size = 64\n",
    "T_size = 30 #28#30#54\n",
    "nw = min([os.cpu_count(), BatchSize if BatchSize > 1 else 0, 6]) \n",
    "print(f'Using {nw} dataloader workers every process.')\n",
    "pin_memory = True\n",
    "train_loader = DataLoader(train_dataset,batch_size=BatchSize,\n",
    "                                           pin_memory=pin_memory,\n",
    "                                           shuffle=True,num_workers=nw)\n",
    "val_loader = DataLoader(val_dataset,batch_size=V_size,\n",
    "                                           pin_memory=pin_memory,\n",
    "                                           shuffle=False,num_workers=nw)\n",
    "test_loader = DataLoader(test_dataset,batch_size=T_size,\n",
    "                                          pin_memory=pin_memory,\n",
    "                                          shuffle=False,num_workers=nw)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation, {} images for testing.\".format(train_num,val_num, test_num))\n",
    "\n",
    "#using 51646 images(augmentation) for training, 1006 images for validation, 828 images for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create capsule network.\n",
    "conv_outputs = 128 #Feature_map\n",
    "num_primary_units = 8\n",
    "primary_unit_size = 16 * 6 * 6  # fixme get from conv2d\n",
    "output_unit_size = 16\n",
    "img_size = 299\n",
    "mode='128'\n",
    "network = FixCapsNet(conv_inputs=n_channels,\n",
    "                     conv_outputs=conv_outputs,\n",
    "                     primary_units=num_primary_units,\n",
    "                     primary_unit_size=primary_unit_size,\n",
    "                     num_classes=n_classes,\n",
    "                     output_unit_size=16,\n",
    "                     init_weights=True,\n",
    "                     mode=mode)\n",
    "network = network.to(device)\n",
    "summary(network,(n_channels,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"%s | %s | %s\" % (\"Model\", \"Params(M)\", \"FLOPs(G)\"))\n",
    "print(\"---|---|---\")\n",
    "name = \"FixCaps\"\n",
    "dsize = (1, 3, 299, 299)\n",
    "inputs = torch.randn(dsize).to(device)\n",
    "total_ops, total_params = profile(network, (inputs,), verbose=False)\n",
    "print(\n",
    "    \"%s | %.2f | %.2f\" % (name, total_params / (1000 ** 2), total_ops / (1000 ** 3))\n",
    "    )\n",
    "#FLOPs(G)--> 0.07(0.08).-->FixCaps-DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network.Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converts batches of class indices to classes of one-hot vectors.\n",
    "def to_one_hot(x, length):\n",
    "    batch_size = x.size(0)\n",
    "    x_one_hot = torch.zeros(batch_size, length)\n",
    "    for i in range(batch_size):\n",
    "        x_one_hot[i, x[i]] = 1.0\n",
    "    return x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(evl_result):\n",
    "    plt.figure(figsize=(16,12))\n",
    "    sb = range(n_classes)\n",
    "    sns.heatmap(evl_result,annot=True,cmap=\"Blues\",cbar=True,fmt=\"g\", annot_kws={\"size\": 20})\n",
    "    plt.yticks([index + 0.5 for index in sb],cla_dict.values(),fontsize=16)\n",
    "    plt.xticks([index + 0.5 for index in sb],cla_dict.values(),fontsize=16)\n",
    "\n",
    "    plt.title(\"Confusion Matrix\",fontsize=24)\n",
    "    cax = plt.gcf().axes[-1]\n",
    "    cax.tick_params(labelsize=16)\n",
    "\n",
    "    # vname = lambda v,nms: [ vn for vn in nms if id(v)==id(nms[vn])][0]\n",
    "    # kn = vname(evl_result,locals())\n",
    "    if evl_result.sum().item() == len(test_dataset):\n",
    "        kn = 'test'\n",
    "    else:\n",
    "        kn = 'val'\n",
    "        \n",
    "    plt.savefig(f\"./tmp/{img_title}/{suf}/Confusion_Matrix_{kn}.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def self_scores(evl_result):\n",
    "    result_table = prettytable.PrettyTable()\n",
    "    result_table.field_names = ['Type','Precision', 'Recall', 'F1','Accuracy']    \n",
    "    accuracy = float(torch.sum(evl_result.diagonal())/torch.sum(evl_result))  \n",
    "    for i in range(n_classes):\n",
    "        pre = float(evl_result[i][i] / torch.sum(evl_result,0)[i])#ÁÐºÍ\n",
    "        recall = float(evl_result[i][i] / torch.sum(evl_result,1)[i])#ÐÐºÍtorch.sum(result_table[i])\n",
    "        F1 = pre * recall * 2 / (pre + recall + 1e-8)\n",
    "        result_table.add_row([cla_dict[i], round(pre, 4), round(recall, 3), round(F1, 3),\" \"])\n",
    "\n",
    "    result_table.add_row([\"Total:\", \" \", \" \", \" \",round(accuracy,4)])\n",
    "    print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "uuid": "86f92f63-16e2-4ca6-b5da-d848546a391e"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    running_loss,r_pre = 0., 0.\n",
    "    print_step = len(train_loader)//2\n",
    "    print(f'\\033[1;32m[Train Epoch:[{epoch}]{img_title} ==> Training]\\033[0m ...')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):        \n",
    "\n",
    "        batch_idx += 1\n",
    "        target_indices = target\n",
    "        target_one_hot = to_one_hot(target, length=n_classes)\n",
    "        data, target = Variable(data).to(device), Variable(target_one_hot).to(device)\n",
    "        # data, target =data.to(device), target_one_hot.to(device)\n",
    "\n",
    "        \n",
    "        # with torch.cuda.amp.autocast():\n",
    "        output = network(data)\n",
    "        loss = network.loss(output, target, size_average=True)\n",
    "        \n",
    "        loss.backward()\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        \n",
    "        if mode == 'DS2':\n",
    "            if batch_idx % 2 == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # scheduler.step()#AdamW\n",
    "        else:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # scheduler.step()#AdamW\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        v_mag = torch.sqrt(torch.sum(output**2, dim=2, keepdim=True)) \n",
    "        pred = v_mag.data.max(1, keepdim=True)[1].cpu().squeeze()\n",
    "        r_pre += pred.eq(target_indices.view_as(pred)).squeeze().sum()\n",
    "        \n",
    "        if batch_idx % print_step == 0:\n",
    "            print(\"[{}/{}] Loss{:.5f},ACC:{:.5f}%\".format(batch_idx,len(train_loader),loss,\n",
    "                                                         r_pre/(batch_idx*BatchSize)))\n",
    "           \n",
    "        \n",
    "    epoch_acc = r_pre / train_num\n",
    "    epoch_loss = running_loss / len(train_loader)  \n",
    "    train_loss_list.append(epoch_loss)\n",
    "    train_acc_list.append(epoch_acc) \n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f'Train Epoch: [{epoch}] Loss: {epoch_loss},Train_acc:{round(float(epoch_acc),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "uuid": "f010e769-677f-416b-8ce8-9f4186dce054"
   },
   "outputs": [],
   "source": [
    "def test(split=\"test\"):\n",
    "    network.eval()\n",
    "    global eval_acc,best_acc,test_evl_result,val_evl_result,evl_tmp_result,net_parameters\n",
    "    cor_loss,correct,Auc, Acc= 0, 0, 0, 0\n",
    "    evl_tmp_result = torch.zeros(n_classes,n_classes)\n",
    "    \n",
    "    if split == 'val':\n",
    "        data_loader = val_loader\n",
    "        tmp_size = V_size\n",
    "        data_num = val_num\n",
    "    else:\n",
    "        data_loader = test_loader\n",
    "        tmp_size = T_size\n",
    "        data_num = test_num\n",
    "        \n",
    "    steps_num = len(data_loader)\n",
    "    print(f'\\033[35m{img_title} ==> {split} ...\\033[0m')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(data_loader)):\n",
    "            batch_idx +=1\n",
    "            target_indices = target#torch.Size([batch, 7])  \n",
    "            target_one_hot = to_one_hot(target, length=n_classes)            \n",
    "            data, target = Variable(data).to(device), Variable(target_one_hot).to(device)\n",
    "\n",
    "            output= network(data)#torch.Size([batch_size, 7, 16, 1])         \n",
    "            v_mag = torch.sqrt(torch.sum(output**2, dim=2, keepdim=True))\n",
    "            pred = v_mag.data.max(1, keepdim=True)[1].cpu()#[9, 2, 1, 1, 6,..., 1, 4, 6, 5, 7,]\n",
    "            \n",
    "            if batch_idx % steps_num == 0 and test_num % tmp_size != 0:\n",
    "                tmp_size = data_num % tmp_size\n",
    "                          \n",
    "            for i in range(tmp_size):\n",
    "                pred_y = pred.numpy()\n",
    "                evl_tmp_result[target_indices[i]][pred_y[i]] +=1 \n",
    "\n",
    "    diag_sum = torch.sum(evl_tmp_result.diagonal())\n",
    "    all_sum = torch.sum(evl_tmp_result) \n",
    "    accuracy = 100. * float(torch.div(diag_sum,all_sum)) \n",
    "    print(f\"{split}_Acc:\\033[1;32m{round(float(accuracy),3)}%\\033[0m\")\n",
    "    \n",
    "    if split == 'val':\n",
    "        val_acc_list.append(accuracy)\n",
    "        if accuracy >= best_acc:\n",
    "            best_acc = accuracy\n",
    "            val_evl_result = evl_tmp_result.clone()#copy.deepcopy(input)\n",
    "            torch.save(network.state_dict(), save_PATH)\n",
    "            torch.save(val_evl_result, f'./tmp/{img_title}/{suf}/best_evl_result.pth')\n",
    "        print(f\"Best_val:\\033[1;32m[{round(float(best_acc),3)}%]\\033[0m\")\n",
    "    else:\n",
    "        test_acc_list.append(accuracy)\n",
    "        if accuracy >= eval_acc:\n",
    "            eval_acc = accuracy\n",
    "            test_evl_result = evl_tmp_result.clone()#copy.deepcopy(input)\n",
    "            torch.save(network.state_dict(), f'./tmp/{img_title}/{suf}/{split}_best_{img_title}_{suf}.pth')\n",
    "            torch.save(test_evl_result, f'./tmp/{img_title}/{suf}/{split}_evl_result.pth')\n",
    "        print(f\"Best_eval:\\033[1;32m[{round(float(eval_acc),3)}%]\\033[0m\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create store\n",
    "try:\n",
    "    print(f\"suf:{suf}\")\n",
    "except NameError:\n",
    "    suf = time.strftime(\"%m%d_%H%M%S\", time.localtime())\n",
    "    print(f\"suf:{suf}\")   \n",
    "if os.path.exists(f'./tmp/{img_title}/{suf}'):\n",
    "    print (f'Store: \"./tmp/{img_title}/{suf}\"')\n",
    "else:\n",
    "    !mkdir -p ./tmp/{img_title}/{suf} \n",
    "save_PATH = f'./tmp/{img_title}/{suf}/new_best_{img_title}_{suf}.pth'\n",
    "print(save_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [],
    "uuid": "edaf3774-de76-44a5-aabd-fb52532ea36e"
   },
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.123\n",
    "def_betas=(0.9, 0.999)\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.AdamW(network.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 5, eta_min=1e-8, last_epoch=-1)\n",
    "\n",
    "#base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0,\n",
    "# scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate,\n",
    "#                         steps_per_epoch=len(train_loader),\n",
    "#                         epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [],
    "uuid": "edaf3774-de76-44a5-aabd-fb52532ea36e"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1): \n",
    "    train(epoch)\n",
    "    test('val')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show.conclusion(opt='val',img_title=img_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "network.load_state_dict(torch.load(save_PATH))\n",
    "\n",
    "for i in range(5):   \n",
    "    test()   \n",
    "show.conclusion(img_title=img_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.memory.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_scores(val_evl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_scores(test_evl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(val_evl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_evl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show.val(write=True,custom_path='./tmp',img_title=img_title,suf=suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show.train(opt='Acc',write=True,custom_path='./tmp',img_title=img_title,suf=suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()#clear photo\n",
    "show.train(write=True,custom_path='./tmp',img_title=img_title,suf=suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #save\n",
    "s0 = np.array(train_acc_list)\n",
    "np.save(f'./tmp/{img_title}/{suf}/{img_title}_train_acc_{suf}.npy', s0)\n",
    "s1 = np.array(train_loss_list)\n",
    "np.save(f'./tmp/{img_title}/{suf}/{img_title}_train_loss_{suf}.npy', s1)\n",
    "s2 = np.array(test_acc_list)\n",
    "np.save(f'./tmp/{img_title}/{suf}/{img_title}_test_acc_{suf}.npy', s2)\n",
    "s3 = np.array(val_acc_list)\n",
    "np.save(f'./tmp/{img_title}/{suf}/{img_title}_val_acc_{suf}.npy', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show.test(write=True,custom_path='./tmp',img_title=img_title,suf=suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.8",
   "language": "python",
   "name": "woodman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
